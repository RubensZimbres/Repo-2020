{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 11, 20, 19, 6, 13, 342551)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas_datareader import data\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "#pip install pandas-datareader\n",
    "import time\n",
    "start=time.time()\n",
    "hoje =  (datetime.datetime.today() - timedelta(days=2))      ##datetime.datetime.today()\n",
    "\n",
    "inicio=(datetime.datetime.today() - timedelta(days=320))\n",
    "data1=str(hoje.year)+'-'+str(hoje.month)+'-'+str(hoje.day)\n",
    "hoje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Nov 15 11:49:27 2020\n",
    "\n",
    "@author: theone\n",
    "\"\"\"\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas_datareader import data\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "#pip install pandas-datareader\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "inicio=(datetime.datetime.today() - timedelta(days=320))#.strftime(\"%Y,%m,%d\")\n",
    "\n",
    "def RSI(dataset, n=14):\n",
    "    delta = dataset.diff()\n",
    "    dUp, dDown = delta.copy(), delta.copy()\n",
    "    dUp[dUp < 0] = 0\n",
    "    dDown[dDown > 0] = 0\n",
    "\n",
    "    RolUp = pd.Series(dUp).rolling(window=n).mean()\n",
    "    RolDown = pd.Series(dDown).rolling(window=n).mean().abs()\n",
    "    RS = RolUp / RolDown\n",
    "    rsi= 100.0 - (100.0 / (1.0 + RS))\n",
    "    return rsi\n",
    "\n",
    "def predict(acao):\n",
    "\n",
    "    try:\n",
    "        if acao=='USDBRL=X' or acao=='^BVSP' or acao=='GC=F' or acao=='CL=F' or acao=='ZS=F' or acao=='SI=F' or acao=='^DJI' or acao=='^IXIC':\n",
    "            stock=acao\n",
    "        else:\n",
    "            stock = '{}.SA'.format(acao)\n",
    "        source = 'yahoo'\n",
    "        source = 'yahoo'\n",
    "        \n",
    "        # Set date range (Google went public August 19, 2004)\n",
    "        start =inicio#datetime.datetime(2020, 3, 1)\n",
    "        end = hoje\n",
    "        \n",
    "        # Collect Google stock data\n",
    "        goog_df = data.DataReader(stock, source, start, end)\n",
    "        \n",
    "        dataset = goog_df['Adj Close']\n",
    "\n",
    "        goog_df['Adj Close'].plot(kind='line', grid=True, title='{} Adjusted Closes, IPO through 2016'.format(stock))\n",
    "        \n",
    "        ## FIBO DINAMICO\n",
    "        max_periodo=np.max(dataset[-144:])\n",
    "        min_periodo=np.min(dataset[-144:])\n",
    "        \n",
    "        diff=max_periodo-min_periodo\n",
    "        \n",
    "        primeiro_fibo=min_periodo+0.328*diff\n",
    "        segundo_fibo=min_periodo+0.618*diff\n",
    "        meio=min_periodo+0.5*diff\n",
    "        media_verde=np.mean(dataset[-15:])\n",
    "        media_vermelha=np.mean(dataset[-21:])\n",
    "        \n",
    "        tendencia=media_verde-media_vermelha\n",
    "        print(acao,tendencia)\n",
    "        fibo_superior=dataset[-1]-segundo_fibo\n",
    "        #limiar_superior=(max_periodo-segundo_fibo)\n",
    "        #limiar_inferior=(primeiro_fibo-min_periodo)\n",
    "        \n",
    "        \n",
    "        fibo_inferior=dataset[-1]-primeiro_fibo\n",
    "        \n",
    "        rsi=RSI(goog_df.Close)[-1]\n",
    "\n",
    "        if tendencia>0 and fibo_inferior>0 and  dataset[-1]>dataset[-5] and dataset[-1]>primeiro_fibo:\n",
    "            output='buy'\n",
    "            print('buy')\n",
    "        elif tendencia<0 and fibo_superior<0 and dataset[-1]<dataset[-5] and dataset[-1]<segundo_fibo:\n",
    "            output='short'\n",
    "            print('short')\n",
    "        else:\n",
    "            output='wait'\n",
    "            print('wait')\n",
    "        close=dataset[-1]\n",
    "        ganho=(max_periodo/segundo_fibo)-1\n",
    "        diferenca=media_verde-media_vermelha\n",
    "        oportunidade=dataset[-1]-meio\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output='NA'\n",
    "        close='NA'\n",
    "        ganho='NA'\n",
    "        diferenca='NA'\n",
    "        oportunidade='NA'\n",
    "        rsi='NA'\n",
    "    return output, close,ganho,diferenca,oportunidade, rsi\n",
    "\n",
    "df=pd.read_csv('Lista_Acoes_Setor.csv',sep=',',header=0)\n",
    "df.columns=['Sigla','Nome_Empresa','Setor']\n",
    "df['Previsao']=np.zeros(df.shape[0])\n",
    "df['Close']=np.zeros(df.shape[0])\n",
    "df['Potencial']=np.zeros(df.shape[0])\n",
    "df['MM_diff']=np.zeros(df.shape[0])\n",
    "df['eixo_xx']=np.zeros(df.shape[0])\n",
    "df['Data']=np.zeros(df.shape[0])\n",
    "df['IFR']=np.zeros(df.shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "    try:#df.shape[0]):\n",
    "        df['Previsao'].iloc[i]=predict(df.iloc[i,0])[0]\n",
    "        df['Close'].iloc[i]=predict(df.iloc[i,0])[1]\n",
    "        df['Potencial'].iloc[i]=predict(df.iloc[i,0])[2]\n",
    "        df['MM_diff'].iloc[i]=predict(df.iloc[i,0])[3]\n",
    "        df['eixo_xx'].iloc[i]=predict(df.iloc[i,0])[4]\n",
    "        df['IFR'].iloc[i]=predict(df.iloc[i,0])[5]\n",
    "        df['Data'].iloc[i]=data1\n",
    "    except:\n",
    "        pass\n",
    "df['Mood']=np.zeros(df.shape[0])\n",
    "\n",
    "for i in range(0,df.shape[0]):\n",
    "    if df['Previsao'][i]=='buy':\n",
    "        df['Mood'][i]=1\n",
    "    if df['Previsao'][i]=='short':\n",
    "        df['Mood'][i]=-1\n",
    "    if df['Previsao'][i]=='wait':\n",
    "        df['Mood'][i]=0\n",
    "    if df['Previsao'][i]=='NA':\n",
    "        df['Mood'][i]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.127867\n",
       "1      0.184273\n",
       "2      0.102712\n",
       "3      0.074230\n",
       "4      0.075133\n",
       "         ...   \n",
       "690    0.000000\n",
       "691    0.000000\n",
       "692    0.000000\n",
       "693    0.000000\n",
       "694    0.000000\n",
       "Name: Potencial, Length: 695, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Potencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "for i in range(0,df.shape[0]):\n",
    "    if df.Previsao[i]=='buy':\n",
    "        df['Mood'][i]=1\n",
    "    elif df.Previsao[i]=='short':\n",
    "        df['Mood'][i]=-1\n",
    "    else:\n",
    "        df['Mood'][i]=0\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.Potencial!='NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Y_ForçaMM']=norm(df.Potencial)\n",
    "df['X_Probabilidade_Fibo']=norm(df.eixo_xx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sigla', 'Nome_Empresa', 'Setor', 'Previsao', 'Close', 'Potencial',\n",
       "       'MM_diff', 'eixo_xx', 'Data', 'IFR', 'Mood', 'Y_ForçaMM',\n",
       "       'X_Probabilidade_Fibo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sigla', 'Nome_Empresa', 'Previsao', 'Close', 'Potencial', 'MM_diff',\n",
    "       'eixo_xx', 'Mood', 'Y_ForçaMM', 'X_Probabilidade_Fibo','Data','Setor','IFR']].to_csv('dataframe_PowerBI.csv',sep=',',index=False,columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sigla', 'Nome_Empresa', 'Setor', 'Previsao', 'Close', 'Potencial',\n",
       "       'MM_diff', 'eixo_xx', 'Data', 'IFR', 'Mood', 'Y_ForçaMM',\n",
       "       'X_Probabilidade_Fibo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "# Construct a BigQuery client object.\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "# table_id = \"your-project.your_dataset.your_table_name\"\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv('dataframe_PowerBI.csv',sep=',',header=0)\n",
    "\n",
    "dataframe=dataframe.dropna(axis=0)\n",
    "dataframe.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Data'] = dataframe['Data'].astype('datetime64[ns]')\n",
    "dataframe.columns=['Sigla', 'Nome_Empresa', 'Setor', 'Previsao', 'Close', 'Potencial',\n",
    "       'MM_diff', 'eixo_xx', 'Data', 'IFR', 'Mood', 'Y_For__aMM',\n",
    "       'X_Probabilidade_Fibo']\n",
    "dataframe=dataframe[['Sigla', 'Nome_Empresa', 'Previsao', 'Close', 'Potencial', 'MM_diff',\n",
    "       'eixo_xx',  'Mood', 'Y_For__aMM', 'X_Probabilidade_Fibo','Data','Setor','IFR']]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"Sigla\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        # Indexes are written if included in the schema by name.\n",
    "        bigquery.SchemaField(\"Nome_Empresa\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Previsao\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"Close\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        bigquery.SchemaField(\"Potencial\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        bigquery.SchemaField(\"MM_diff\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        bigquery.SchemaField(\"eixo_xx\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        bigquery.SchemaField(\"Mood\", bigquery.enums.SqlTypeNames.INTEGER),\n",
    "        bigquery.SchemaField(\"Y_For__aMM\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        bigquery.SchemaField(\"X_Probabilidade_Fibo\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        bigquery.SchemaField(\"Data\", bigquery.enums.SqlTypeNames.DATE),\n",
    "        bigquery.SchemaField(\"Setor\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"IFR\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_APPEND\",\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(\n",
    "    dataframe, 'machinelearning.fibo.fibinha', job_config=job_config\n",
    ")  # Make an API request.\n",
    "job.result()  # Wait for the job to complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
